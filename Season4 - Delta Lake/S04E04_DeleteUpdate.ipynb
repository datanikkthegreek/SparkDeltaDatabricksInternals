{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from delta import configure_spark_with_delta_pip\n",
    "from delta.tables import DeltaTable\n",
    "from pyspark.sql import functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Data with Nikk the Greek Spark Session\") \\\n",
    "    .master(\"local[4]\") \\\n",
    "    .config(\"spark.jars.packages\", \"uk.co.gresearch.spark:spark-extension_2.12:2.11.0-3.5\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.spark:spark-avro_2.12:3.5.0\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark DataFrameWriter: https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrameWriter.mode.html#pyspark.sql.DataFrameWriter.mode\n",
    "\n",
    "Spark to Delta mapping: https://docs.delta.io/latest/releases.html\n",
    "Dataframe Reader and Writer versions: https://docs.delta.io/latest/versioning.html\n",
    "\n",
    "Get Started: https://delta.io/learn/getting-started/\n",
    "\n",
    "Deletes, Updates, Merges: https://docs.delta.io/latest/delta-update.html#language-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_delta = \"D:/Data/delta_test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a table and overwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = spark.range(start=1, end=6, numPartitions=1)\n",
    "sdf = sdf.withColumn(\"name\", f.lit(\"Nikk\"))\n",
    "sdf.write.format(\"delta\").mode(\"overwrite\").save(path_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+\n",
      "| id|name|\n",
      "+---+----+\n",
      "|  1|Nikk|\n",
      "|  2|Nikk|\n",
      "|  3|Nikk|\n",
      "|  4|Nikk|\n",
      "|  5|Nikk|\n",
      "+---+----+\n",
      "\n",
      "+------+------------------------------------+----+-----------+------------------------+-----------------------+-----------------------+----------------+--------+-----------+----------+----------------+----------------+------------------------+\n",
      "|format|id                                  |name|description|location                |createdAt              |lastModified           |partitionColumns|numFiles|sizeInBytes|properties|minReaderVersion|minWriterVersion|tableFeatures           |\n",
      "+------+------------------------------------+----+-----------+------------------------+-----------------------+-----------------------+----------------+--------+-----------+----------+----------------+----------------+------------------------+\n",
      "|delta |be104872-c059-4164-9bc4-a0ed0a890f7a|NULL|NULL       |file:/D:/Data/delta_test|2024-05-07 20:16:41.302|2024-05-07 20:16:41.535|[]              |1       |773        |{}        |1               |2               |[appendOnly, invariants]|\n",
      "+------+------------------------------------+----+-----------+------------------------+-----------------------+-----------------------+----------------+--------+-----------+----------+----------------+----------------+------------------------+\n",
      "\n",
      "+-------+-----------------------+------+--------+---------+--------------------------------------+----+--------+---------+-----------+--------------+-------------+----------------------------------------------------------+------------+-----------------------------------+\n",
      "|version|timestamp              |userId|userName|operation|operationParameters                   |job |notebook|clusterId|readVersion|isolationLevel|isBlindAppend|operationMetrics                                          |userMetadata|engineInfo                         |\n",
      "+-------+-----------------------+------+--------+---------+--------------------------------------+----+--------+---------+-----------+--------------+-------------+----------------------------------------------------------+------------+-----------------------------------+\n",
      "|0      |2024-05-07 20:16:41.535|NULL  |NULL    |WRITE    |{mode -> Overwrite, partitionBy -> []}|NULL|NULL    |NULL     |NULL       |Serializable  |false        |{numFiles -> 1, numOutputRows -> 5, numOutputBytes -> 773}|NULL        |Apache-Spark/3.5.1 Delta-Lake/3.1.0|\n",
      "+-------+-----------------------+------+--------+---------+--------------------------------------+----+--------+---------+-----------+--------------+-------------+----------------------------------------------------------+------------+-----------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.format(\"delta\").load(path_delta).show()\n",
    "deltaTable = DeltaTable.forPath(spark, path_delta)\n",
    "deltaTable.detail().show(20, False)\n",
    "deltaTable.history().show(20, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Append data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = spark.range(start=6, end=11, numPartitions=1)\n",
    "sdf = sdf.withColumn(\"name\", f.lit(\"Marko\"))\n",
    "sdf.write.format(\"delta\").mode(\"append\").save(path_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "| id| name|\n",
      "+---+-----+\n",
      "|  6|Marko|\n",
      "|  7|Marko|\n",
      "|  8|Marko|\n",
      "|  9|Marko|\n",
      "| 10|Marko|\n",
      "|  1| Nikk|\n",
      "|  2| Nikk|\n",
      "|  3| Nikk|\n",
      "|  4| Nikk|\n",
      "|  5| Nikk|\n",
      "+---+-----+\n",
      "\n",
      "+------+------------------------------------+----+-----------+------------------------+-----------------------+-----------------------+----------------+--------+-----------+----------+----------------+----------------+------------------------+\n",
      "|format|id                                  |name|description|location                |createdAt              |lastModified           |partitionColumns|numFiles|sizeInBytes|properties|minReaderVersion|minWriterVersion|tableFeatures           |\n",
      "+------+------------------------------------+----+-----------+------------------------+-----------------------+-----------------------+----------------+--------+-----------+----------+----------------+----------------+------------------------+\n",
      "|delta |be104872-c059-4164-9bc4-a0ed0a890f7a|NULL|NULL       |file:/D:/Data/delta_test|2024-05-07 20:16:41.302|2024-05-07 20:16:47.393|[]              |2       |1551       |{}        |1               |2               |[appendOnly, invariants]|\n",
      "+------+------------------------------------+----+-----------+------------------------+-----------------------+-----------------------+----------------+--------+-----------+----------+----------------+----------------+------------------------+\n",
      "\n",
      "+-------+-----------------------+------+--------+---------+--------------------------------------+----+--------+---------+-----------+--------------+-------------+----------------------------------------------------------+------------+-----------------------------------+\n",
      "|version|timestamp              |userId|userName|operation|operationParameters                   |job |notebook|clusterId|readVersion|isolationLevel|isBlindAppend|operationMetrics                                          |userMetadata|engineInfo                         |\n",
      "+-------+-----------------------+------+--------+---------+--------------------------------------+----+--------+---------+-----------+--------------+-------------+----------------------------------------------------------+------------+-----------------------------------+\n",
      "|1      |2024-05-07 20:16:47.393|NULL  |NULL    |WRITE    |{mode -> Append, partitionBy -> []}   |NULL|NULL    |NULL     |0          |Serializable  |true         |{numFiles -> 1, numOutputRows -> 5, numOutputBytes -> 778}|NULL        |Apache-Spark/3.5.1 Delta-Lake/3.1.0|\n",
      "|0      |2024-05-07 20:16:41.535|NULL  |NULL    |WRITE    |{mode -> Overwrite, partitionBy -> []}|NULL|NULL    |NULL     |NULL       |Serializable  |false        |{numFiles -> 1, numOutputRows -> 5, numOutputBytes -> 773}|NULL        |Apache-Spark/3.5.1 Delta-Lake/3.1.0|\n",
      "+-------+-----------------------+------+--------+---------+--------------------------------------+----+--------+---------+-----------+--------------+-------------+----------------------------------------------------------+------------+-----------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.format(\"delta\").load(path_delta).show()\n",
    "deltaTable = DeltaTable.forPath(spark, path_delta)\n",
    "deltaTable.detail().show(20, False)\n",
    "deltaTable.history().show(20, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "deltaTable = DeltaTable.forPath(spark, path_delta)\n",
    "\n",
    "# Using SQL formatted string\n",
    "deltaTable.delete(\"id == 1\")\n",
    "\n",
    "# Using Spark SQL functions\n",
    "#deltaTable.delete(f.col(\"id\") == 1)\n",
    "\n",
    "# Using SQL\n",
    "#spark.sql(f\"DELETE FROM delta.`{path_delta}` WHERE id == 1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "| id| name|\n",
      "+---+-----+\n",
      "|  6|Marko|\n",
      "|  7|Marko|\n",
      "|  8|Marko|\n",
      "|  9|Marko|\n",
      "| 10|Marko|\n",
      "|  2| Nikk|\n",
      "|  3| Nikk|\n",
      "|  4| Nikk|\n",
      "|  5| Nikk|\n",
      "+---+-----+\n",
      "\n",
      "+------+------------------------------------+----+-----------+------------------------+-----------------------+-----------------------+----------------+--------+-----------+----------+----------------+----------------+------------------------+\n",
      "|format|id                                  |name|description|location                |createdAt              |lastModified           |partitionColumns|numFiles|sizeInBytes|properties|minReaderVersion|minWriterVersion|tableFeatures           |\n",
      "+------+------------------------------------+----+-----------+------------------------+-----------------------+-----------------------+----------------+--------+-----------+----------+----------------+----------------+------------------------+\n",
      "|delta |be104872-c059-4164-9bc4-a0ed0a890f7a|NULL|NULL       |file:/D:/Data/delta_test|2024-05-07 20:16:41.302|2024-05-07 20:16:57.734|[]              |2       |1545       |{}        |1               |2               |[appendOnly, invariants]|\n",
      "+------+------------------------------------+----+-----------+------------------------+-----------------------+-----------------------+----------------+--------+-----------+----------+----------------+----------------+------------------------+\n",
      "\n",
      "+-------+-----------------------+------+--------+---------+--------------------------------------+----+--------+---------+-----------+--------------+-------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+-----------------------------------+\n",
      "|version|timestamp              |userId|userName|operation|operationParameters                   |job |notebook|clusterId|readVersion|isolationLevel|isBlindAppend|operationMetrics                                                                                                                                                                                                                                                                                                          |userMetadata|engineInfo                         |\n",
      "+-------+-----------------------+------+--------+---------+--------------------------------------+----+--------+---------+-----------+--------------+-------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+-----------------------------------+\n",
      "|2      |2024-05-07 20:16:57.734|NULL  |NULL    |DELETE   |{predicate -> [\"(id#25454L = 1)\"]}    |NULL|NULL    |NULL     |1          |Serializable  |false        |{numRemovedFiles -> 1, numRemovedBytes -> 773, numCopiedRows -> 4, numDeletionVectorsAdded -> 0, numDeletionVectorsRemoved -> 0, numAddedChangeFiles -> 0, executionTimeMs -> 380, numDeletionVectorsUpdated -> 0, numDeletedRows -> 1, scanTimeMs -> 254, numAddedFiles -> 1, numAddedBytes -> 767, rewriteTimeMs -> 126}|NULL        |Apache-Spark/3.5.1 Delta-Lake/3.1.0|\n",
      "|1      |2024-05-07 20:16:47.393|NULL  |NULL    |WRITE    |{mode -> Append, partitionBy -> []}   |NULL|NULL    |NULL     |0          |Serializable  |true         |{numFiles -> 1, numOutputRows -> 5, numOutputBytes -> 778}                                                                                                                                                                                                                                                                |NULL        |Apache-Spark/3.5.1 Delta-Lake/3.1.0|\n",
      "|0      |2024-05-07 20:16:41.535|NULL  |NULL    |WRITE    |{mode -> Overwrite, partitionBy -> []}|NULL|NULL    |NULL     |NULL       |Serializable  |false        |{numFiles -> 1, numOutputRows -> 5, numOutputBytes -> 773}                                                                                                                                                                                                                                                                |NULL        |Apache-Spark/3.5.1 Delta-Lake/3.1.0|\n",
      "+-------+-----------------------+------+--------+---------+--------------------------------------+----+--------+---------+-----------+--------------+-------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+-----------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.format(\"delta\").load(path_delta).show()\n",
    "deltaTable = DeltaTable.forPath(spark, path_delta)\n",
    "deltaTable.detail().show(20, False)\n",
    "deltaTable.history().show(20, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "deltaTable = DeltaTable.forPath(spark, path_delta)\n",
    "\n",
    "# Using SQL formatted string\n",
    "deltaTable.update(condition = \"id = 7\", set = { \"name\": \"'Strahinja'\"})\n",
    "\n",
    "# Using Spark SQL functions\n",
    "#deltaTable.update(condition = f.col(\"id\") == 7, set = { \"name\": f.lit(\"Strahinja\")})\n",
    "\n",
    "# Using SQL\n",
    "#spark.sql(f\"UPDATE delta.`{path_delta}` SET name = 'Strahinja' WHERE id == 7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+\n",
      "| id|     name|\n",
      "+---+---------+\n",
      "|  6|    Marko|\n",
      "|  7|Strahinja|\n",
      "|  8|    Marko|\n",
      "|  9|    Marko|\n",
      "| 10|    Marko|\n",
      "|  2|     Nikk|\n",
      "|  3|     Nikk|\n",
      "|  4|     Nikk|\n",
      "|  5|     Nikk|\n",
      "+---+---------+\n",
      "\n",
      "+------+------------------------------------+----+-----------+------------------------+-----------------------+-----------------------+----------------+--------+-----------+----------+----------------+----------------+------------------------+\n",
      "|format|id                                  |name|description|location                |createdAt              |lastModified           |partitionColumns|numFiles|sizeInBytes|properties|minReaderVersion|minWriterVersion|tableFeatures           |\n",
      "+------+------------------------------------+----+-----------+------------------------+-----------------------+-----------------------+----------------+--------+-----------+----------+----------------+----------------+------------------------+\n",
      "|delta |be104872-c059-4164-9bc4-a0ed0a890f7a|NULL|NULL       |file:/D:/Data/delta_test|2024-05-07 20:16:41.302|2024-05-07 20:17:03.585|[]              |2       |1554       |{}        |1               |2               |[appendOnly, invariants]|\n",
      "+------+------------------------------------+----+-----------+------------------------+-----------------------+-----------------------+----------------+--------+-----------+----------+----------------+----------------+------------------------+\n",
      "\n",
      "+-------+-----------------------+------+--------+---------+--------------------------------------+----+--------+---------+-----------+--------------+-------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+-----------------------------------+\n",
      "|version|timestamp              |userId|userName|operation|operationParameters                   |job |notebook|clusterId|readVersion|isolationLevel|isBlindAppend|operationMetrics                                                                                                                                                                                                                                                                                                          |userMetadata|engineInfo                         |\n",
      "+-------+-----------------------+------+--------+---------+--------------------------------------+----+--------+---------+-----------+--------------+-------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+-----------------------------------+\n",
      "|3      |2024-05-07 20:17:03.585|NULL  |NULL    |UPDATE   |{predicate -> [\"(id#26933L = 7)\"]}    |NULL|NULL    |NULL     |2          |Serializable  |false        |{numRemovedFiles -> 1, numRemovedBytes -> 778, numCopiedRows -> 4, numDeletionVectorsAdded -> 0, numDeletionVectorsRemoved -> 0, numAddedChangeFiles -> 0, executionTimeMs -> 384, numDeletionVectorsUpdated -> 0, scanTimeMs -> 241, numAddedFiles -> 1, numUpdatedRows -> 1, numAddedBytes -> 787, rewriteTimeMs -> 142}|NULL        |Apache-Spark/3.5.1 Delta-Lake/3.1.0|\n",
      "|2      |2024-05-07 20:16:57.734|NULL  |NULL    |DELETE   |{predicate -> [\"(id#25454L = 1)\"]}    |NULL|NULL    |NULL     |1          |Serializable  |false        |{numRemovedFiles -> 1, numRemovedBytes -> 773, numCopiedRows -> 4, numDeletionVectorsAdded -> 0, numDeletionVectorsRemoved -> 0, numAddedChangeFiles -> 0, executionTimeMs -> 380, numDeletionVectorsUpdated -> 0, numDeletedRows -> 1, scanTimeMs -> 254, numAddedFiles -> 1, numAddedBytes -> 767, rewriteTimeMs -> 126}|NULL        |Apache-Spark/3.5.1 Delta-Lake/3.1.0|\n",
      "|1      |2024-05-07 20:16:47.393|NULL  |NULL    |WRITE    |{mode -> Append, partitionBy -> []}   |NULL|NULL    |NULL     |0          |Serializable  |true         |{numFiles -> 1, numOutputRows -> 5, numOutputBytes -> 778}                                                                                                                                                                                                                                                                |NULL        |Apache-Spark/3.5.1 Delta-Lake/3.1.0|\n",
      "|0      |2024-05-07 20:16:41.535|NULL  |NULL    |WRITE    |{mode -> Overwrite, partitionBy -> []}|NULL|NULL    |NULL     |NULL       |Serializable  |false        |{numFiles -> 1, numOutputRows -> 5, numOutputBytes -> 773}                                                                                                                                                                                                                                                                |NULL        |Apache-Spark/3.5.1 Delta-Lake/3.1.0|\n",
      "+-------+-----------------------+------+--------+---------+--------------------------------------+----+--------+---------+-----------+--------------+-------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+-----------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.format(\"delta\").load(path_delta).show()\n",
    "deltaTable = DeltaTable.forPath(spark, path_delta)\n",
    "deltaTable.detail().show(20, False)\n",
    "deltaTable.history().show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
