{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from delta import configure_spark_with_delta_pip\n",
    "from delta.tables import DeltaTable\n",
    "from pyspark.sql import functions as f\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Data with Nikk the Greek Spark Session\") \\\n",
    "    .master(\"local[4]\") \\\n",
    "    .config(\"spark.jars.packages\", \"uk.co.gresearch.spark:spark-extension_2.12:2.11.0-3.5\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.spark:spark-avro_2.12:3.5.0\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark DataFrameWriter: https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrameWriter.mode.html#pyspark.sql.DataFrameWriter.mode\n",
    "\n",
    "Spark to Delta mapping: https://docs.delta.io/latest/releases.html\n",
    "Dataframe Reader and Writer versions: https://docs.delta.io/latest/versioning.html\n",
    "\n",
    "Get Started: https://delta.io/learn/getting-started/\n",
    "\n",
    "Deletes, Updates, Merges: https://docs.delta.io/latest/delta-update.html#language-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_delta = \"D:/Data/delta_test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a table and overwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = spark.range(start=1, end=6, numPartitions=1)\n",
    "sdf = sdf.withColumn(\"name\", f.lit(\"Nikk\"))\n",
    "sdf.write.format(\"delta\").mode(\"overwrite\").save(path_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+\n",
      "| id|name|\n",
      "+---+----+\n",
      "|  1|Nikk|\n",
      "|  2|Nikk|\n",
      "|  3|Nikk|\n",
      "|  4|Nikk|\n",
      "|  5|Nikk|\n",
      "+---+----+\n",
      "\n",
      "+------+------------------------------------+----+-----------+------------------------+-----------------------+-----------------------+----------------+--------+-----------+----------+----------------+----------------+------------------------+\n",
      "|format|id                                  |name|description|location                |createdAt              |lastModified           |partitionColumns|numFiles|sizeInBytes|properties|minReaderVersion|minWriterVersion|tableFeatures           |\n",
      "+------+------------------------------------+----+-----------+------------------------+-----------------------+-----------------------+----------------+--------+-----------+----------+----------------+----------------+------------------------+\n",
      "|delta |0c92253f-b3e9-421b-aab3-83530419b76a|NULL|NULL       |file:/D:/Data/delta_test|2024-05-07 21:03:51.495|2024-05-07 21:03:57.359|[]              |1       |773        |{}        |1               |2               |[appendOnly, invariants]|\n",
      "+------+------------------------------------+----+-----------+------------------------+-----------------------+-----------------------+----------------+--------+-----------+----------+----------------+----------------+------------------------+\n",
      "\n",
      "+-------+-----------------------+------+--------+---------+--------------------------------------+----+--------+---------+-----------+--------------+-------------+----------------------------------------------------------+------------+-----------------------------------+\n",
      "|version|timestamp              |userId|userName|operation|operationParameters                   |job |notebook|clusterId|readVersion|isolationLevel|isBlindAppend|operationMetrics                                          |userMetadata|engineInfo                         |\n",
      "+-------+-----------------------+------+--------+---------+--------------------------------------+----+--------+---------+-----------+--------------+-------------+----------------------------------------------------------+------------+-----------------------------------+\n",
      "|0      |2024-05-07 21:03:57.359|NULL  |NULL    |WRITE    |{mode -> Overwrite, partitionBy -> []}|NULL|NULL    |NULL     |NULL       |Serializable  |false        |{numFiles -> 1, numOutputRows -> 5, numOutputBytes -> 773}|NULL        |Apache-Spark/3.5.1 Delta-Lake/3.1.0|\n",
      "+-------+-----------------------+------+--------+---------+--------------------------------------+----+--------+---------+-----------+--------------+-------------+----------------------------------------------------------+------------+-----------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.format(\"delta\").load(path_delta).show()\n",
    "deltaTable = DeltaTable.forPath(spark, path_delta)\n",
    "deltaTable.detail().show(20, False)\n",
    "deltaTable.history().show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:/Data/delta_test/_delta_log/part-00000-7de78df9-2f39-46e9-a345-1364f2eaef27-c000.snappy.parquet']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_parquet = [f\"{path_delta}/_delta_log/{f}\" for f in os.listdir(f\"{path_delta}\") if f.split(\".\")[-1] == \"parquet\"]\n",
    "files_parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Append data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = spark.range(start=6, end=11, numPartitions=1)\n",
    "sdf = sdf.withColumn(\"name\", f.lit(\"Marko\"))\n",
    "sdf.write.format(\"delta\").mode(\"append\").save(path_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "| id| name|\n",
      "+---+-----+\n",
      "|  6|Marko|\n",
      "|  7|Marko|\n",
      "|  8|Marko|\n",
      "|  9|Marko|\n",
      "| 10|Marko|\n",
      "|  1| Nikk|\n",
      "|  2| Nikk|\n",
      "|  3| Nikk|\n",
      "|  4| Nikk|\n",
      "|  5| Nikk|\n",
      "+---+-----+\n",
      "\n",
      "+------+------------------------------------+----+-----------+------------------------+-----------------------+-----------------------+----------------+--------+-----------+----------+----------------+----------------+------------------------+\n",
      "|format|id                                  |name|description|location                |createdAt              |lastModified           |partitionColumns|numFiles|sizeInBytes|properties|minReaderVersion|minWriterVersion|tableFeatures           |\n",
      "+------+------------------------------------+----+-----------+------------------------+-----------------------+-----------------------+----------------+--------+-----------+----------+----------------+----------------+------------------------+\n",
      "|delta |0c92253f-b3e9-421b-aab3-83530419b76a|NULL|NULL       |file:/D:/Data/delta_test|2024-05-07 21:03:51.495|2024-05-07 21:05:08.598|[]              |2       |1551       |{}        |1               |2               |[appendOnly, invariants]|\n",
      "+------+------------------------------------+----+-----------+------------------------+-----------------------+-----------------------+----------------+--------+-----------+----------+----------------+----------------+------------------------+\n",
      "\n",
      "+-------+-----------------------+------+--------+---------+--------------------------------------+----+--------+---------+-----------+--------------+-------------+----------------------------------------------------------+------------+-----------------------------------+\n",
      "|version|timestamp              |userId|userName|operation|operationParameters                   |job |notebook|clusterId|readVersion|isolationLevel|isBlindAppend|operationMetrics                                          |userMetadata|engineInfo                         |\n",
      "+-------+-----------------------+------+--------+---------+--------------------------------------+----+--------+---------+-----------+--------------+-------------+----------------------------------------------------------+------------+-----------------------------------+\n",
      "|1      |2024-05-07 21:05:08.598|NULL  |NULL    |WRITE    |{mode -> Append, partitionBy -> []}   |NULL|NULL    |NULL     |0          |Serializable  |true         |{numFiles -> 1, numOutputRows -> 5, numOutputBytes -> 778}|NULL        |Apache-Spark/3.5.1 Delta-Lake/3.1.0|\n",
      "|0      |2024-05-07 21:03:57.359|NULL  |NULL    |WRITE    |{mode -> Overwrite, partitionBy -> []}|NULL|NULL    |NULL     |NULL       |Serializable  |false        |{numFiles -> 1, numOutputRows -> 5, numOutputBytes -> 773}|NULL        |Apache-Spark/3.5.1 Delta-Lake/3.1.0|\n",
      "+-------+-----------------------+------+--------+---------+--------------------------------------+----+--------+---------+-----------+--------------+-------------+----------------------------------------------------------+------------+-----------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.format(\"delta\").load(path_delta).show()\n",
    "deltaTable = DeltaTable.forPath(spark, path_delta)\n",
    "deltaTable.detail().show(20, False)\n",
    "deltaTable.history().show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:/Data/delta_test/_delta_log/part-00000-4917efc4-6f13-4108-b0f3-021e8116f1cf-c000.snappy.parquet',\n",
       " 'D:/Data/delta_test/_delta_log/part-00000-7de78df9-2f39-46e9-a345-1364f2eaef27-c000.snappy.parquet']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_parquet = [f\"{path_delta}/_delta_log/{f}\" for f in os.listdir(f\"{path_delta}\") if f.split(\".\")[-1] == \"parquet\"]\n",
    "files_parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "deltaTable = DeltaTable.forPath(spark, path_delta)\n",
    "\n",
    "# Using SQL formatted string\n",
    "deltaTable.delete(\"id == 1\")\n",
    "\n",
    "# Using Spark SQL functions\n",
    "#deltaTable.delete(f.col(\"id\") == 1)\n",
    "\n",
    "# Using SQL\n",
    "#spark.sql(f\"DELETE FROM delta.`{path_delta}` WHERE id == 1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "| id| name|\n",
      "+---+-----+\n",
      "|  6|Marko|\n",
      "|  7|Marko|\n",
      "|  8|Marko|\n",
      "|  9|Marko|\n",
      "| 10|Marko|\n",
      "|  2| Nikk|\n",
      "|  3| Nikk|\n",
      "|  4| Nikk|\n",
      "|  5| Nikk|\n",
      "+---+-----+\n",
      "\n",
      "+------+------------------------------------+----+-----------+------------------------+-----------------------+-----------------------+----------------+--------+-----------+----------+----------------+----------------+------------------------+\n",
      "|format|id                                  |name|description|location                |createdAt              |lastModified           |partitionColumns|numFiles|sizeInBytes|properties|minReaderVersion|minWriterVersion|tableFeatures           |\n",
      "+------+------------------------------------+----+-----------+------------------------+-----------------------+-----------------------+----------------+--------+-----------+----------+----------------+----------------+------------------------+\n",
      "|delta |0c92253f-b3e9-421b-aab3-83530419b76a|NULL|NULL       |file:/D:/Data/delta_test|2024-05-07 21:03:51.495|2024-05-07 21:06:49.812|[]              |2       |1545       |{}        |1               |2               |[appendOnly, invariants]|\n",
      "+------+------------------------------------+----+-----------+------------------------+-----------------------+-----------------------+----------------+--------+-----------+----------+----------------+----------------+------------------------+\n",
      "\n",
      "+-------+-----------------------+------+--------+---------+--------------------------------------+----+--------+---------+-----------+--------------+-------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+-----------------------------------+\n",
      "|version|timestamp              |userId|userName|operation|operationParameters                   |job |notebook|clusterId|readVersion|isolationLevel|isBlindAppend|operationMetrics                                                                                                                                                                                                                                                                                                          |userMetadata|engineInfo                         |\n",
      "+-------+-----------------------+------+--------+---------+--------------------------------------+----+--------+---------+-----------+--------------+-------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+-----------------------------------+\n",
      "|2      |2024-05-07 21:06:49.812|NULL  |NULL    |DELETE   |{predicate -> [\"(id#2726L = 1)\"]}     |NULL|NULL    |NULL     |1          |Serializable  |false        |{numRemovedFiles -> 1, numRemovedBytes -> 773, numCopiedRows -> 4, numDeletionVectorsAdded -> 0, numDeletionVectorsRemoved -> 0, numAddedChangeFiles -> 0, executionTimeMs -> 980, numDeletionVectorsUpdated -> 0, numDeletedRows -> 1, scanTimeMs -> 814, numAddedFiles -> 1, numAddedBytes -> 767, rewriteTimeMs -> 165}|NULL        |Apache-Spark/3.5.1 Delta-Lake/3.1.0|\n",
      "|1      |2024-05-07 21:05:08.598|NULL  |NULL    |WRITE    |{mode -> Append, partitionBy -> []}   |NULL|NULL    |NULL     |0          |Serializable  |true         |{numFiles -> 1, numOutputRows -> 5, numOutputBytes -> 778}                                                                                                                                                                                                                                                                |NULL        |Apache-Spark/3.5.1 Delta-Lake/3.1.0|\n",
      "|0      |2024-05-07 21:03:57.359|NULL  |NULL    |WRITE    |{mode -> Overwrite, partitionBy -> []}|NULL|NULL    |NULL     |NULL       |Serializable  |false        |{numFiles -> 1, numOutputRows -> 5, numOutputBytes -> 773}                                                                                                                                                                                                                                                                |NULL        |Apache-Spark/3.5.1 Delta-Lake/3.1.0|\n",
      "+-------+-----------------------+------+--------+---------+--------------------------------------+----+--------+---------+-----------+--------------+-------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+-----------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.format(\"delta\").load(path_delta).show()\n",
    "deltaTable = DeltaTable.forPath(spark, path_delta)\n",
    "deltaTable.detail().show(20, False)\n",
    "deltaTable.history().show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:/Data/delta_test/_delta_log/part-00000-4917efc4-6f13-4108-b0f3-021e8116f1cf-c000.snappy.parquet',\n",
       " 'D:/Data/delta_test/_delta_log/part-00000-7de78df9-2f39-46e9-a345-1364f2eaef27-c000.snappy.parquet',\n",
       " 'D:/Data/delta_test/_delta_log/part-00000-dd9d11d7-d441-4f7e-8483-429591e0d13a-c000.snappy.parquet']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_parquet = [f\"{path_delta}/_delta_log/{f}\" for f in os.listdir(f\"{path_delta}\") if f.split(\".\")[-1] == \"parquet\"]\n",
    "files_parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "deltaTable = DeltaTable.forPath(spark, path_delta)\n",
    "\n",
    "# Using SQL formatted string\n",
    "deltaTable.update(condition = \"id = 7\", set = { \"name\": \"'Strahinja'\"})\n",
    "\n",
    "# Using Spark SQL functions\n",
    "#deltaTable.update(condition = f.col(\"id\") == 7, set = { \"name\": f.lit(\"Strahinja\")})\n",
    "\n",
    "# Using SQL\n",
    "#spark.sql(f\"UPDATE delta.`{path_delta}` SET name = 'Strahinja' WHERE id == 7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+\n",
      "| id|     name|\n",
      "+---+---------+\n",
      "|  6|    Marko|\n",
      "|  7|Strahinja|\n",
      "|  8|    Marko|\n",
      "|  9|    Marko|\n",
      "| 10|    Marko|\n",
      "|  2|     Nikk|\n",
      "|  3|     Nikk|\n",
      "|  4|     Nikk|\n",
      "|  5|     Nikk|\n",
      "+---+---------+\n",
      "\n",
      "+------+------------------------------------+----+-----------+------------------------+-----------------------+-----------------------+----------------+--------+-----------+----------+----------------+----------------+------------------------+\n",
      "|format|id                                  |name|description|location                |createdAt              |lastModified           |partitionColumns|numFiles|sizeInBytes|properties|minReaderVersion|minWriterVersion|tableFeatures           |\n",
      "+------+------------------------------------+----+-----------+------------------------+-----------------------+-----------------------+----------------+--------+-----------+----------+----------------+----------------+------------------------+\n",
      "|delta |0c92253f-b3e9-421b-aab3-83530419b76a|NULL|NULL       |file:/D:/Data/delta_test|2024-05-07 21:03:51.495|2024-05-07 21:10:22.701|[]              |2       |1554       |{}        |1               |2               |[appendOnly, invariants]|\n",
      "+------+------------------------------------+----+-----------+------------------------+-----------------------+-----------------------+----------------+--------+-----------+----------+----------------+----------------+------------------------+\n",
      "\n",
      "+-------+-----------------------+------+--------+---------+--------------------------------------+----+--------+---------+-----------+--------------+-------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+-----------------------------------+\n",
      "|version|timestamp              |userId|userName|operation|operationParameters                   |job |notebook|clusterId|readVersion|isolationLevel|isBlindAppend|operationMetrics                                                                                                                                                                                                                                                                                                          |userMetadata|engineInfo                         |\n",
      "+-------+-----------------------+------+--------+---------+--------------------------------------+----+--------+---------+-----------+--------------+-------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+-----------------------------------+\n",
      "|3      |2024-05-07 21:10:22.701|NULL  |NULL    |UPDATE   |{predicate -> [\"(id#4206L = 7)\"]}     |NULL|NULL    |NULL     |2          |Serializable  |false        |{numRemovedFiles -> 1, numRemovedBytes -> 778, numCopiedRows -> 4, numDeletionVectorsAdded -> 0, numDeletionVectorsRemoved -> 0, numAddedChangeFiles -> 0, executionTimeMs -> 788, numDeletionVectorsUpdated -> 0, scanTimeMs -> 576, numAddedFiles -> 1, numUpdatedRows -> 1, numAddedBytes -> 787, rewriteTimeMs -> 211}|NULL        |Apache-Spark/3.5.1 Delta-Lake/3.1.0|\n",
      "|2      |2024-05-07 21:06:49.812|NULL  |NULL    |DELETE   |{predicate -> [\"(id#2726L = 1)\"]}     |NULL|NULL    |NULL     |1          |Serializable  |false        |{numRemovedFiles -> 1, numRemovedBytes -> 773, numCopiedRows -> 4, numDeletionVectorsAdded -> 0, numDeletionVectorsRemoved -> 0, numAddedChangeFiles -> 0, executionTimeMs -> 980, numDeletionVectorsUpdated -> 0, numDeletedRows -> 1, scanTimeMs -> 814, numAddedFiles -> 1, numAddedBytes -> 767, rewriteTimeMs -> 165}|NULL        |Apache-Spark/3.5.1 Delta-Lake/3.1.0|\n",
      "|1      |2024-05-07 21:05:08.598|NULL  |NULL    |WRITE    |{mode -> Append, partitionBy -> []}   |NULL|NULL    |NULL     |0          |Serializable  |true         |{numFiles -> 1, numOutputRows -> 5, numOutputBytes -> 778}                                                                                                                                                                                                                                                                |NULL        |Apache-Spark/3.5.1 Delta-Lake/3.1.0|\n",
      "|0      |2024-05-07 21:03:57.359|NULL  |NULL    |WRITE    |{mode -> Overwrite, partitionBy -> []}|NULL|NULL    |NULL     |NULL       |Serializable  |false        |{numFiles -> 1, numOutputRows -> 5, numOutputBytes -> 773}                                                                                                                                                                                                                                                                |NULL        |Apache-Spark/3.5.1 Delta-Lake/3.1.0|\n",
      "+-------+-----------------------+------+--------+---------+--------------------------------------+----+--------+---------+-----------+--------------+-------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+-----------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.format(\"delta\").load(path_delta).show()\n",
    "deltaTable = DeltaTable.forPath(spark, path_delta)\n",
    "deltaTable.detail().show(20, False)\n",
    "deltaTable.history().show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:/Data/delta_test/_delta_log/part-00000-08ccc96a-c37b-44e3-821e-a9cab09798bd-c000.snappy.parquet',\n",
       " 'D:/Data/delta_test/_delta_log/part-00000-4917efc4-6f13-4108-b0f3-021e8116f1cf-c000.snappy.parquet',\n",
       " 'D:/Data/delta_test/_delta_log/part-00000-7de78df9-2f39-46e9-a345-1364f2eaef27-c000.snappy.parquet',\n",
       " 'D:/Data/delta_test/_delta_log/part-00000-dd9d11d7-d441-4f7e-8483-429591e0d13a-c000.snappy.parquet']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_parquet = [f\"{path_delta}/_delta_log/{f}\" for f in os.listdir(f\"{path_delta}\") if f.split(\".\")[-1] == \"parquet\"]\n",
    "files_parquet"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
